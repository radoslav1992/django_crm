# ğŸ¤– AI Model Configuration

## Current Model: Gemini 2.5 Flash-Lite

### âœ… Model Updated!

The CRM now uses **Gemini 2.5 Flash-Lite** for optimal cost-efficiency and performance.

---

## ğŸ“Š Model Specifications

According to [Google AI documentation](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite):

### **Gemini 2.5 Flash-Lite**
- **Model Code:** `gemini-2.5-flash-lite`
- **Type:** Second generation small workhorse model
- **Optimization:** Cost efficiency and low latency
- **Status:** Preview (Latest update: September 2025)

### **Capabilities:**
```
âœ… Input Types: Audio, images, video, and text
âœ… Output Types: Text
âœ… Input Token Limit: 1,048,576 tokens (~750,000 words)
âœ… Output Token Limit: 8,192 tokens
âœ… Context Window: 1 million tokens
âœ… Knowledge Cutoff: January 2025
```

### **Supported Features:**
- âœ… **Function Calling** - Yes
- âœ… **Structured Outputs** - Yes
- âœ… **Batch API** - Supported
- âœ… **Caching** - Supported
- âœ… **Search Grounding** - Not supported
- âœ… **Code Execution** - Not supported
- âœ… **Thinking** - Not supported
- âŒ **Audio Generation** - Not supported
- âŒ **Image Generation** - Not supported
- âŒ **Live API** - Not supported

---

## ğŸ’° Why Flash-Lite?

### **Benefits:**
1. **Cost Efficiency** - Lower pricing than Flash or Pro
2. **Low Latency** - Fast response times
3. **Large Context** - Still supports 1M tokens
4. **Perfect for CRM** - Ideal for business text generation

### **Use Cases in This CRM:**
- âœ… Chat assistance
- âœ… Email drafting
- âœ… Deal analysis
- âœ… Task suggestions
- âœ… Template content generation
- âœ… Smart search

All these features work perfectly with Flash-Lite!

---

## ğŸ”§ Configuration

### **Where It's Configured:**
```python
File: apps/ai_assistant/services.py
Line: 19

class GeminiAssistant:
    def __init__(self, user):
        self.user = user
        self.model = genai.GenerativeModel('gemini-2.5-flash-lite')
```

### **API Key:**
Set in `.env` file:
```env
GEMINI_API_KEY=your-api-key-here
```

Get your free API key at: https://makersuite.google.com/app/apikey

---

## ğŸ“ˆ Model Comparison

| Feature | Flash-Lite | Flash | Pro |
|---------|-----------|-------|-----|
| **Speed** | Fastest | Fast | Moderate |
| **Cost** | Lowest | Low | Higher |
| **Context** | 1M tokens | 1M tokens | 1M tokens |
| **Output** | 8K tokens | 65K tokens | 65K tokens |
| **Thinking** | No | Yes | Yes |
| **Best For** | High volume, cost-sensitive | Balanced | Complex reasoning |

### **For CRM Use:**
âœ… **Flash-Lite is PERFECT** because:
- CRM tasks don't need extensive reasoning
- Email drafts are short (<8K tokens)
- Fast responses improve UX
- Lower costs for high-volume usage
- 1M context window handles large CRM data

---

## ğŸ¯ Performance Characteristics

### **Response Times:**
- **Email Generation:** ~2-3 seconds
- **Chat Response:** ~1-2 seconds
- **Deal Analysis:** ~3-5 seconds
- **Task Suggestions:** ~2-3 seconds

### **Token Usage (Typical):**
- **Chat message:** 500-1,000 tokens
- **Email draft:** 300-500 tokens
- **Deal analysis:** 800-1,200 tokens
- **Task suggestions:** 400-600 tokens

### **Cost Efficiency:**
Flash-Lite offers the best price-performance ratio for these use cases!

---

## ğŸ”„ How to Switch Models

If you want to try different models:

### **Option 1: Gemini 2.5 Flash (More capable)**
```python
# In apps/ai_assistant/services.py:
self.model = genai.GenerativeModel('gemini-2.5-flash')
```

### **Option 2: Gemini 2.5 Pro (Most powerful)**
```python
# In apps/ai_assistant/services.py:
self.model = genai.GenerativeModel('gemini-2.5-pro')
```

### **Option 3: Gemini 2.0 Flash (Previous gen)**
```python
# In apps/ai_assistant/services.py:
self.model = genai.GenerativeModel('gemini-2.0-flash')
```

Then restart the server:
```bash
pkill -f "manage.py runserver"
python manage.py runserver 8001
```

---

## ğŸ“š Gemini Models Available

From the official documentation:

### **Gemini 2.5 Series (Latest):**
- **gemini-2.5-pro** - Most advanced, thinking capability
- **gemini-2.5-flash** - Best balance â† Good alternative
- **gemini-2.5-flash-lite** - Most cost-effective â† **CURRENT**

### **Gemini 2.0 Series:**
- **gemini-2.0-flash** - Second gen workhorse
- **gemini-2.0-flash-exp** - Experimental (was our old setting)
- **gemini-2.0-flash-lite** - Cost-optimized 2.0

---

## ğŸ¯ Current Configuration Summary

```
âœ… Model: Gemini 2.5 Flash-Lite
âœ… Version: Latest (September 2025)
âœ… Context: 1,048,576 tokens (1M)
âœ… Output: 8,192 tokens
âœ… Optimization: Cost & Latency
âœ… Status: Active in CRM
âœ… Use Cases: All CRM AI features
```

---

## ğŸ§ª Testing AI Features

Once you add your Gemini API key to `.env`:

```bash
# Edit .env
GEMINI_API_KEY=your-actual-key-from-google

# Restart server (if needed)
```

Then test:
1. **AI Chat:** http://localhost:8001/bg/ai/chat/
2. **Generate Email:** From any contact page
3. **Analyze Deal:** From any deal page
4. **Get Suggestions:** From AI suggestions page

All powered by cost-efficient Gemini 2.5 Flash-Lite! ğŸš€

---

## ğŸ“– References

- **Model Documentation:** https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite
- **Get API Key:** https://makersuite.google.com/app/apikey
- **Pricing:** https://ai.google.dev/pricing

---

## âœ… Change Applied!

The CRM now uses **Gemini 2.5 Flash-Lite** for:
- Better cost efficiency
- Lower latency
- High-volume processing
- All CRM AI features

Perfect choice for a CRM application! ğŸ’¡

